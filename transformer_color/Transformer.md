# åŸºäºAIçš„æ„ŸçŸ¥è‰²å·®é¢„æµ‹æ¨¡å‹

æœ¬å·¥ä½œæ—¨åœ¨åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ‹Ÿåˆæ—§æœ‰è‰²å½©å¿ƒç†ç‰©ç†å®éªŒä¸­çš„â€œäººç±»æ„ŸçŸ¥è‰²å·®â€ï¼ˆhuman perceptual color differenceï¼‰ã€‚ä¼ ç»Ÿè‰²å·®å…¬å¼ï¼ˆå¦‚ Î”E76 / Î”E94 / Î”E2000ï¼‰å‡ä¸ºäººå·¥è®¾è®¡ï¼Œè€Œ AI æ¨¡å‹èƒ½å¤Ÿä»è·¨æ•°æ®é›†çš„å®éªŒæ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ æ›´ç¬¦åˆäººç±»ä¸»è§‚è§†è§‰ä¸€è‡´æ€§çš„è‰²å·®åº¦é‡ã€‚

ä»¥ä¸‹ä¸ºå®Œæ•´çš„é¡¹ç›®è¯´æ˜æ–‡æ¡£ã€‚

## 1. æ•°æ®é›†å‡†å¤‡ï¼ˆDatasetsï¼‰

ä¸ºäº†æ„å»ºç»Ÿä¸€ä¸”è¦†ç›–è¶³å¤Ÿå¤šé¢œè‰²å¯¹çš„è®­ç»ƒæ•°æ®ï¼Œæˆ‘ä»¬ä½¿ç”¨ GitHub ä¸Š Coloria æ•´åˆä»“åº“ï¼š

ğŸ”— [https://github.com/coloria-dev/color-data](https://github.com/coloria-dev/color-data)

ä»ä¸­é€‰æ‹©äº† 1980â€“1990 å¹´ä»£æœ€ç»å…¸ã€ä½¿ç”¨æœ€å¹¿çš„å¿ƒç†ç‰©ç†å®éªŒæ•°æ®é›†ï¼š

| æ•°æ®é›†          | å…‰æº | è¯´æ˜                                                         |
| --------------- | ---- | ------------------------------------------------------------ |
| bfd-c.json      | C    | Bradford Universityï¼ˆè‹±å›½å¸ƒæ‹‰å¾·ç¦å¾·å¤§å­¦ï¼‰ Fosterç­‰è‰²å½©ç§‘å­¦å®¶å›¢é˜Ÿ |
| bfd-d65.json    | D65  |                                                              |
| bfd-m.json      | M    |                                                              |
| leeds.json      | D65  | University of Leedsï¼ˆåˆ©å…¹å¤§å­¦ï¼‰ è‹±å›½æœ€å¼ºçš„è‰²å½©ç§‘å­¦å®éªŒå®¤ä¹‹ä¸€ |
| rit-dupont.json |      | RITâ€“DuPont æ±½è½¦æ¶‚æ–™å®éªŒ                                      |
| witt.json       |      | Witt å®éªŒ                                                    |

æœ€ç»ˆæ•°æ®ç›®å½•ç»“æ„ï¼š

```
datasets/
â”œâ”€ bfd-c.json
â”œâ”€ bfd-d65.json
â”œâ”€ bfd-m.json
â”œâ”€ rit-dupont.json
â”œâ”€ leeds.json
â””â”€ witt.json
```

### 1.1 æ•°æ®æ ¼å¼ï¼ˆç»Ÿä¸€ JSON ç»“æ„ï¼‰

æ¯ä¸ª JSON æ–‡ä»¶å‡åŒ…å«ï¼š

```
{
    "reference_white": [],
    "dv": [],      // äººç±»æ„ŸçŸ¥å·®å¼‚è¯„åˆ† (difference values)
    "pairs": [],   // ç´¢å¼•å¯¹ (i, j)ï¼šè¡¨ç¤ºé¢œè‰² xyz[i], xyz[j]
    "xyz": []      // æ‰€æœ‰ XYZ é¢œè‰²æ ·æœ¬
}
```

åŠ è½½åè½¬æ¢ä¸ºæœ€ç»ˆè®­ç»ƒæ ¼å¼ï¼š

```
L1, a1, b1, L2, a2, b2 â†’ DE_human
```

å…¶ä¸­ Lab ä½¿ç”¨ `colormath` ä»¥ D65ã€2Â° observer è½¬æ¢ã€‚

---

## 2.æ¨¡å‹è¾“å…¥ / è¾“å‡ºè®¾è®¡

**è¾“å…¥ç‰¹å¾ï¼ˆFeature Designï¼‰**

```
(L1, a1, b1, L2, a2, b2)
```

è¾“å…¥ä¸ºä¸¤ç»„ Lab é¢œè‰²æ‹¼æ¥ï¼Œå¹¶ reshape ä¸ºï¼š

```
batch Ã— 2 Ã— 3
```

ä»¥ä¾¿é€å…¥ Transformer ä½œä¸ºä¸¤ä¸ª tokenã€‚

**è¾“å‡ºï¼ˆTargetï¼‰**

```
y_pred âˆˆ â„  # æ¨¡å‹é¢„æµ‹çš„äººç±»è§†è§‰è‰²å·® Î”E_vis
```

æ­¤ Î”E_vis ä¸æ˜¯ä»»ä½•å·²æœ‰è‰²å·®å…¬å¼ï¼Œè€Œæ˜¯ç›´æ¥æ‹Ÿåˆå®éªŒä¸­çš„â€œä¸»è§‚å·®å¼‚è¯„åˆ†â€ã€‚

### 2.1 é‡è¦çš„æ•°æ®é¢„å¤„ç†

ä¸ºäº†ä½¿è®­ç»ƒæ›´åŠ ç¨³å®šï¼Œä½¿ç”¨ï¼š

- **log(1+Î”E)** æŠ‘åˆ¶é•¿å°¾åˆ†å¸ƒ
- **æ ‡å‡†åŒ–ï¼ˆz-scoreï¼‰** æå‡è®­ç»ƒé€Ÿåº¦
- **æŒ‰ Î”E åŒºé—´é‡‡æ ·ï¼ˆbalanced samplingï¼‰** è®©æ¨¡å‹åœ¨å°å·®å¼‚åŒºåŸŸï¼ˆäººç±»æ•æ„ŸåŒºåŸŸï¼‰å­¦ä¹ æ›´å¤š

---

## 3. æ¨¡å‹ç»“æ„ï¼ˆTransformer for Color Differenceï¼‰

æœ¬é¡¹ç›®ä¸€å¼€å§‹é‡‡ç”¨ä¸€ä¸ªè½»é‡çº§ Transformer ç¼–ç å™¨ï¼Œç”¨äºå­¦ä¹ ä¸¤ä¸ªé¢œè‰² token çš„å…³ç³»ï¼š

```python
import torch
import torch.nn as nn

class ColorTransformer(nn.Module):
    def __init__(self, dim=32, depth=4, heads=4):
        super().__init__()

        self.embed = nn.Linear(3, dim)  # Lab â†’ embedding

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=dim,
            nhead=heads,
            dim_feedforward=128,
            batch_first=True
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)

        self.fc = nn.Linear(dim * 2, 1)  # flatten embeddings â†’ scalar output

    def forward(self, x):
        # x: (batch, 2, 3)
        e = self.embed(x)
        out = self.encoder(e)
        out = out.reshape(out.shape[0], -1)
        return self.fc(out)
```

åæ¥å‘ç°æ‹Ÿåˆæ•ˆæœä¸æ˜¯ç‰¹åˆ«å¥½

* **Transformer æ˜¯åºåˆ—å»ºæ¨¡ç»“æ„ï¼ˆattention sequence modelï¼‰**

* **Siamese æ¶æ„å¤©ç”Ÿé€‚åˆ metric learningï¼ˆåº¦é‡å­¦ä¹ ï¼‰**

Siamese ç¼–ç å™¨ + è·ç¦» MLP é¢„æµ‹

```python
class SiameseColorNet(nn.Module):
    def __init__(self, emb_dim=128):
        super().__init__()
        # (L,a,b) â†’ åµŒå…¥å‘é‡
        self.encoder = nn.Sequential(
            nn.Linear(3, 64),
            nn.ReLU(),
            nn.Linear(64, emb_dim),
            nn.ReLU()
        )
        # |e1 - e2| â†’ é¢„æµ‹ log1p(DE)ï¼ˆå½’ä¸€åŒ–åçš„ï¼‰
        self.head = nn.Sequential(
            nn.Linear(emb_dim, emb_dim//2),
            nn.ReLU(),
            nn.Linear(emb_dim//2, 1)
        )

    def forward(self, x):
        B = x.shape[0]
        colors = x.view(B, 2, 3)
        c1, c2 = colors[:,0,:], colors[:,1,:]
        e1, e2 = self.encoder(c1), self.encoder(c2)
        d = torch.abs(e1 - e2)
        out = self.head(d).squeeze(-1)
        return out

model = SiameseColorNet(emb_dim=128).to(DEVICE)
opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)
loss_fn = nn.HuberLoss(delta=1.0)
```



## 4. åŸºçº¿è‰²å·®å…¬å¼ï¼ˆBenchmarkï¼‰

ä¸ºäº†è¯„ä¼°æ¨¡å‹æ˜¯å¦çœŸæ­£â€œæ¯” Î”E æ›´åƒäººç±»â€ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹åŸºçº¿ï¼š

| Baseline | è¯´æ˜                   |
| -------- | ---------------------- |
| Î”E76     | æ¬§æ°è·ç¦»               |
| Î”E94     | å·¥ä¸šè‰²å·®               |
| Î”E2000   | å½“å‰æœ€å¸¸ç”¨             |
| OKLab Î”E | perceptual color space |

### 4.1 Oklab Î”E

```python
def oklab_de(l1,a1,b1,l2,a2,b2):
    return np.sqrt((l1-l2)**2 + (a1-a2)**2 + (b1-b2)**2)
```

### 4.2 Î”E2000

```python
from colormath.color_objects import LabColor
from colormath.color_diff import delta_e_cie2000

def de2000(row):
    c1 = LabColor(row.L1, row.a1, row.b1)
    c2 = LabColor(row.L2, row.a2, row.b2)
    return delta_e_cie2000(c1, c2)
```

---

## 5. è¯„ä»·æŒ‡æ ‡ï¼ˆEvaluation Metricsï¼‰

ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•° Pearson R è¡¡é‡æ¨¡å‹è¾“å‡ºä¸äººç±»å®éªŒçš„ç›¸å…³æ€§ï¼š

```
from scipy.stats import pearsonr

r = pearsonr(true_values, predicted_values)[0]
```

---

## 6. å¯è§†åŒ–ä¸å®éªŒç»“æœï¼ˆVisualizationï¼‰

### 6.1 æ•£ç‚¹å›¾ï¼šAI vs Human

```
plt.figure()
plt.scatter(true_all, preds_un, s=6, alpha=0.4)
plt.xlabel("Human score (Î”E raw)")
plt.ylabel("Model prediction (Î”E raw)")
plt.title(f"Siamese Model vs Human (R={r_model:.4f})")
plt.plot([0, max(true_all.max(), preds_un.max())], [0, max(true_all.max(), preds_un.max())], 'r--', linewidth=1)
plt.savefig("scatter_siamese_pred_vs_human.png", dpi=150)
plt.close()
```

<img src="./images/scatter_siamese_pred_vs_human.png" style="zoom: 50%;" />

### 6.2 è¯¯å·®ç›´æ–¹å›¾ï¼ˆerror histï¼‰

```
err = (preds_un.ravel() - true_all.ravel())
plt.figure()
sns.histplot(err, bins=80, kde=True)
plt.title("Prediction error (pred - human)")
plt.savefig("hist_error_siamese.png", dpi=150)
plt.close()
```

<img src="./images/hist_error_siamese.png" style="zoom:50%;" />

### 6.3 Rå€¼å¯¹æ¯”å›¾ï¼ˆR comparison barï¼‰

```
plt.figure()
labels = ["Siamese", "Î”E2000"]
vals = [r_model, r_de2000]
sns.barplot(x=labels, y=vals)
plt.ylim(0,1)
plt.title("Pearson R comparison")
plt.savefig("r_comparison_siamese.png", dpi=150)
plt.close()
```

<img src="./images/r_comparison_siamese.png" style="zoom:50%;" />

### 6.4 å®éªŒç»“æœ

å½“å‰æ¨¡å‹ï¼ˆç»è¿‡ log-scaling + balanced sampling + Huber Lossï¼‰ï¼š

```
R(model)   = 0.9253
R(DE2000)  = 0.7754
```

AI æ¨¡å‹æ˜¾è‘—è¶…è¶Š DE2000ï¼ˆâ‰ˆ +0.15ï¼‰ï¼Œè¾¾åˆ°æ¥è¿‘äººç±»é—´ä¸€è‡´æ€§ï¼ˆinter-observer consistency â‰ˆ 0.90â€“0.95ï¼‰ã€‚

è¯´æ˜æ¨¡å‹ç¡®å®åœ¨å­¦ä¹ â€œäººç±»è§†è§‰æ„ŸçŸ¥â€ï¼Œè€Œä¸ä»…ä»…æ˜¯ Lab å‡ ä½•è·ç¦»ã€‚
